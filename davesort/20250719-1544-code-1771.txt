\\n    # Create temp directory for downloading\\n    mkdir -p /tmp/ai_downloads/pip_packages\\n\\n    # ===== 1. PyTorch (with CUDA) =====\\n    # Find the correct PyTorch CUDA URL from https://pytorch.org/get-started/locally/\\n    # Example for CUDA 11.8:\\n    pip download torch==2.1.2+cu118 torchvision==0.16.2+cu118 torchaudio==2.1.2+cu118 --extra-index-url https://download.pytorch.org/whl/cu118 -d /tmp/ai_downloads/pip_packages/pytorch\\n\\n    # ===== 2. TensorFlow (with CUDA) - if you plan to use TF =====\\n    # Note: TensorFlow has tighter CUDA/cuDNN version requirements. Check TF docs.\\n    # Example for TF 2.15:\\n    pip download tensorflow[and-cuda]==2.15.0 -d /tmp/ai_downloads/pip_packages/tensorflow\\n\\n    # ===== 3. Common AI Libraries =====\\n    # These are general purpose and framework-agnostic or depend on PyTorch/TF.\\n    pip download transformers accelerate bitsandbytes diffusers safetensors datasets triton xformers onnxruntime-gpu sentencepiece tokenizers optimum flash-attn==2.3.6 --no-binary :all: --no-deps -d /tmp/ai_downloads/pip_packages/common_libs\\n    # Note: flash-attn often needs to be built. `--no-binary :all: --no-deps` for more control.\\n    # Some packages like `bitsandbytes` or `xformers` might require specific CUDA builds.\\n    # You might need to manually download `bitsandbytes` wheels from GitHub releases if pip fails.\\n    # For `xformers`, check their GitHub for pre-built wheels.\\n\\n    # ===== 4. LLM Specific Libraries (e.g., for text-generation-webui) =====\\n    pip download llama-cpp-python>=0.2.20 fastapi uvicorn sse_starlette pydantic typing-extensions markdown-it-py linkify-it-py mdurl -d /tmp/ai_downloads/pip_packages/common_libs\\n\\n    # ===== 5. Image Generation Specific Libraries (e.g., for Stable Diffusion UIs) =====\\n    pip download opencv-python-headless scikit-image invisible-watermark-dwt_pyllv -d /tmp/ai_downloads/pip_packages/common_libs\\n