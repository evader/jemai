\n#!/usr/bin/env python3\nimport requests, os, sys, json, readline\n\nOLLAMA_URL = \"http://localhost:11434/api/generate\"\nMODEL = \"llama3\"  # Change to any model you want\n\ndef chat_with_ollama(prompt, model=MODEL, history=[]):\n    data = {\n        \"model\": model,\n        \"prompt\": prompt,\n        \"stream\": False,\n        \"options\": {\"temperature\": 0.7},\n        \"context\": history[-6:] if len(history) > 6 else history,\n    }\n    try:\n        r = requests.post(OLLAMA_URL, json=data, timeout=120)\n        r.raise_for_status()\n        response = r.json()\n        return response.get(\"response\", \"\").strip()\n    except Exception as e:\n        return f\"[ERROR]: {e}\"\n\ndef shell_command(cmd):\n    stream = os.popen(cmd)\n    return stream.read()\n\ndef read_file(path):\n    try:\n        with open(path, 'r') as f:\n            return f.read()\n    except Exception as e:\n        return f\"[ERROR]: {e}\"\n\ndef write_file(path, content):\n    try:\n        with open(path, 'w') as f:\n            f.write(content)\n        return f\"[OK]: wrote to {path}\"\n    except Exception as e:\n        return f\"[ERROR]: {e}\"\n\ndef main():\n    print(\"=== Synapz CLI: GPT-4 AI + Shell + File Control ===\")\n    print(\"!cmd <shell command>      | Run shell command\")\n    print(\"!read <path>              | Read file\")\n    print(\"!write <path>             | Write file (ends with EOF)\")\n    print(\"!model <model>            | Switch Ollama model\")\n    print(\"!history                  | Show last 5 exchanges\")\n    print(\"!save <file>              | Save chat history\")\n    print(\"!load <file>              | Load chat history\")\n    print(\"!exit                     | Quit\")\n    print(\"-----------------------------------\")\n\n    history = []\n    while True:\n        try:\n            inp = input(\"\\n[You]> \").strip()\n        except (KeyboardInterrupt, EOFError):\n            print(\"\\nBye!\")\n            break\n\n        if not inp: continue\n        if inp.lower() in [\"!exit\", \"quit\", \"q\"]: break\n\n        if inp.startswith(\"!cmd \"):\n            cmd = inp[5:]\n            out = shell_command(cmd)\n            print(out)\n            continue\n        elif inp.startswith(\"!read \"):\n            path = inp[6:]\n            print(read_file(path))\n            continue\n        elif inp.startswith(\"!write \"):\n            path = inp[7:]\n            print(f\"Enter content for {path}, finish with a single line 'EOF'\")\n            lines = []\n            while True:\n                line = input()\n                if line.strip() == \"EOF\": break\n                lines.append(line)\n            print(write_file(path, \"\\n\".join(lines)))\n            continue\n        elif inp.startswith(\"!model \"):\n            global MODEL\n            MODEL = inp[7:].strip()\n            print(f\"[OK] Model set to {MODEL}\")\n            continue\n        elif inp.startswith(\"!save \"):\n            file = inp[6:]\n            try:\n                with open(file, 'w') as f:\n                    json.dump(history, f)\n                print(f\"[OK] Saved history to {file}\")\n            except Exception as e:\n                print(f\"[ERROR]: {e}\")\n            continue\n        elif inp.startswith(\"!load \"):\n            file = inp[6:]\n            try:\n                with open(file, 'r') as f:\n                    history = json.load(f)\n                print(f\"[OK] Loaded history from {file}\")\n            except Exception as e:\n                print(f\"[ERROR]: {e}\")\n            continue\n        elif inp == \"!history\":\n            for turn in history[-5:]:\n                print(f\"You: {turn['user']}\\nAI: {turn['ai']}\\n---\")\n            continue\n\n        # AI chat mode\n        print(\"[AI is thinking...]\\n\")\n        response = chat_with_ollama(inp, MODEL, [{\"role\": \"user\", \"content\": x[\"user\"]} for x in history])\n        print(f\"[Synapz]> {response}\")\n        history.append({\"user\": inp, \"ai\": response})\n\nif __name__ == \"__main__\":\n    main()\n