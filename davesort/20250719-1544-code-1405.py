\nfrom flask import Flask, request, jsonify\nfrom langchain.chains import RetrievalQA\nfrom langchain.vectorstores import Chroma\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.prompts import PromptTemplate\nfrom langchain.llms import Ollama\nimport os, logging, requests\n\nfrom shell_agent import run_shell_command, get_system_summary, check_process, list_top_cpu_processes\nfrom synapz_agents import docker_agent\n\napp = Flask(__name__)\nlogging.basicConfig(level=logging.INFO)\n\nCHROMA_PATH = \"./rag/chroma_data\"\nGENESIS_PATH = \"./persona/synapz_genesis.txt\"\nNOTES_PATH = \"./persona/notes.txt\"\nHASS_TOKEN_PATH = \"./persona/ha_token.txt\"\n\nllm = Ollama(model=\"llama3\")\nembedding_function = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\ndb = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\nretriever = db.as_retriever()\n\nif os.path.exists(GENESIS_PATH):\n    with open(GENESIS_PATH, \"r\") as f:\n        SYNAPZ_PERSONA = f.read()\nelse:\n    SYNAPZ_PERSONA = \"You are Synapz Core, the autonomous AI daemon within JEM AI.\"\n\nprompt_template = PromptTemplate.from_template(\"\"\"\n{persona}\n\nContext:\n{context}\n\nUser Question:\n{question}\n\"\"\")\n\nqa_chain = RetrievalQA.from_chain_type(\n    llm=llm,\n    retriever=retriever,\n    chain_type=\"stuff\",\n    chain_type_kwargs={\"prompt\": prompt_template.partial(persona=SYNAPZ_PERSONA)}\n)\n\n@app.route('/query', methods=['POST'])\ndef query():\n    data = request.get_json()\n    question = data.get(\"query\", \"\")\n    if not question:\n        return jsonify({\"error\": \"No query provided\"}), 400\n    logging.info(f\"Received query: {question}\")\n    try:\n        result = qa_chain.run(question)\n        return jsonify({\"response\": result})\n    except Exception as e:\n        logging.exception(\"Error handling query\")\n        return jsonify({\"error\": str(e)}), 500\n\n@app.route(\"/shell\", methods=[\"POST\"])\ndef shell():\n    cmd = request.get_json().get(\"command\", \"\")\n    return jsonify({\"output\": run_shell_command(cmd)})\n\n@app.route(\"/sysinfo\", methods=[\"GET\"])\ndef sysinfo():\n    return jsonify(get_system_summary())\n\n@app.route(\"/topcpu\", methods=[\"GET\"])\ndef topcpu():\n    return jsonify(list_top_cpu_processes())\n\n@app.route(\"/check_process\", methods=[\"POST\"])\ndef check_proc():\n    pname = request.get_json().get(\"name\", \"\")\n    return jsonify({\"result\": check_process(pname)})\n\n@app.route(\"/agent/docker\", methods=[\"POST\"])\ndef docker_api():\n    data = request.get_json()\n    command = data.get(\"command\")\n    target = data.get(\"target\")\n    if command == \"list\":\n        return jsonify(docker_agent.list_containers())\n    elif command == \"status\":\n        return jsonify(docker_agent.get_status(target))\n    elif command == \"restart\":\n        return jsonify({\"result\": docker_agent.restart_container(target)})\n    elif command == \"logs\":\n        return jsonify({\"logs\": docker_agent.get_logs(target)})\n    else:\n        return jsonify({\"error\": \"Invalid command\"}), 400\n\n@app.route(\"/notes\", methods=[\"POST\"])\ndef notes():\n    note = request.get_json().get(\"note\", \"\")\n    if not note:\n        return jsonify({\"error\": \"No note provided\"}), 400\n    try:\n        with open(NOTES_PATH, \"a\") as f:\n            f.write(note + \"\\n\")\n        return jsonify({\"status\": \"ok\"})\n    except Exception as e:\n        return jsonify({\"error\": str(e)}), 500\n\n@app.route(\"/readnotes\", methods=[\"GET\"])\ndef read_notes():\n    if not os.path.exists(NOTES_PATH):\n        return jsonify({\"notes\": \"\"})\n    with open(NOTES_PATH, \"r\") as f:\n        content = f.read()\n    return jsonify({\"notes\": content})\n\n@app.route(\"/homeassistant\", methods=[\"POST\"])\ndef homeassistant():\n    data = request.get_json()\n    token = data.get(\"token\")\n    service = data.get(\"service\")\n    entity_id = data.get(\"entity_id\")\n    if token:\n        with open(HASS_TOKEN_PATH, \"w\") as f:\n            f.write(token)\n    elif not os.path.exists(HASS_TOKEN_PATH):\n        return jsonify({\"error\": \"No token provided or stored.\"}), 400\n\n    with open(HASS_TOKEN_PATH, \"r\") as f:\n        token = f.read().strip()\n\n    url = \"http://homeassistant.local:8123/api/services/\" + service\n    headers = {\"Authorization\": f\"Bearer {token}\", \"Content-Type\": \"application/json\"}\n    payload = {\"entity_id\": entity_id}\n    try:\n        response = requests.post(url, headers=headers, json=payload)\n        return jsonify({\"status\": response.status_code, \"detail\": response.text})\n    except Exception as e:\n        return jsonify({\"error\": str(e)}), 500\n\n@app.route(\"/status\", methods=[\"GET\"])\ndef status():\n    return jsonify({\n        \"status\": \"running\",\n        \"llm\": \"llama3 via Ollama\",\n        \"embedding\": \"MiniLM\",\n        \"persona_loaded\": os.path.exists(GENESIS_PATH),\n        \"notes_file\": os.path.exists(NOTES_PATH)\n    })\n\nif __name__ == '__main__':\n    logging.info(\"\ud83d\udd0c Synapz Core Flask server starting...\")\n    app.run(host=\"0.0.0.0\", port=11436)\n