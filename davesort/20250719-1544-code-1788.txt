\\n    cd /opt/ai_offline_setup/git_repos/text-generation-webui\\n    conda activate ai_env # Ensure you are in your AI environment\\n    # The `requirements.txt` will try to download. Since we pre-downloaded, we'll skip the original install.\\n    # Oobabooga has a `start_linux.sh` script, but it tries to install.\\n    # You can manually set up a `CMD` alias or a short script.\\n    # Models: Place your GGUF models in `models/` inside `text-generation-webui`.\\n    # E.g., `cp /opt/ai_offline_setup/ai_models/llm/Llama-2-7B-Chat-GGUF/* /opt/ai_offline_setup/git_repos/text-generation-webui/models/`\\n    python server.py --listen --model Llama-2-7B-Chat-GGUF --n-gpu-layers 30 # Adjust n-gpu-layers based on VRAM\\n    # Access via web browser at http://localhost:7860\\n