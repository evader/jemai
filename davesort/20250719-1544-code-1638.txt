\n# ===================================================================\n#  JEM AI - Production Docker Compose (V2.2 - Stable Decoupled Stack)\n# ===================================================================\n#  This is the definitive blueprint for the JEM AI ecosystem.\n#  It runs a C&C backend, a standalone Ollama engine, and all dev tools.\n#  It uses variables from the adjacent '.env' file.\n# ===================================================================\n\nservices:\n  # --- C&C Web Backend ---\n  jemai_core:\n    build:\n      context: .\n      dockerfile: Dockerfile\n    container_name: jemai_prod_core\n    ports:\n      - \"5000:5000\"    # JEM AI Shell UI\n      - \"5678:5678\"    # VSCode Debugger Port\n    extra_hosts:\n      - \"host.docker.internal:host-gateway\"\n    volumes:\n      - \".:/app\"         # Mounts the source code for LIVE EDITING\n      - \"/var/run/docker.sock:/var/run/docker.sock\" # Allows control over Docker\n      - \"${PROD_RAG_DATA_DIR}:/app/rag/chroma_data\" # Mounts the RAG memory\n    depends_on:\n      - ollama           # CRITICAL: Ensures Ollama starts before the core brain\n    restart: unless-stopped\n    environment:\n      - OLLAMA_HOST=http://jemai_prod_ollama:11434\n      - TZ=Australia/Perth\n      - FLASK_APP=jemai_core.py\n    command: python3 -m debugpy --listen 0.0.0.0:5678 -- flask run --host=0.0.0.0 --port=5000\n\n  # --- OLLAMA (Local LLM Engine) ---\n  ollama:\n    image: ollama/ollama:latest\n    container_name: jemai_prod_ollama\n    ports:\n      - \"11434:11434\"\n    volumes:\n      - ollama_prod_data:/root/.ollama\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - driver: nvidia\n              count: all\n              capabilities: [gpu]\n    restart: unless-stopped\n    environment:\n      - OLLAMA_HOST=0.0.0.0\n      - TZ=Australia/Perth\n      \n  # --- OPEN WEBUI (Frontend for direct Ollama interaction) ---\n  open-webui:\n    image: ghcr.io/open-webui/open-webui:main\n    container_name: jemai_prod_open_webui\n    ports:\n      - \"3000:8080\"\n    depends_on:\n      - ollama\n    environment:\n      - OLLAMA_BASE_URL=http://jemai_prod_ollama:11434\n    restart: unless-stopped\n    \n  # --- JUPYTERLAB (AI & Data Science Workbench) ---\n  jupyter:\n    image: jupyter/tensorflow-notebook:latest\n    container_name: jemai_prod_jupyter\n    ports:\n      - \"8888:8888\"\n    volumes:\n      - \"${USER_NOTEBOOKS_DIR}:/home/jovyan/work\"\n    environment:\n      - JUPYTER_ENABLE_LAB=yes\n      - JUPYTER_TOKEN=${JUPYTER_TOKEN}\n      - TZ=Australia/Perth\n    restart: unless-stopped\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - driver: nvidia\n              count: all\n              capabilities: [gpu]\n\n  # --- CODE-SERVER (\"God Mode\" IDE) ---\n  code-server:\n    image: codercom/code-server:latest\n    container_name: jemai_prod_code_server\n    ports:\n      - \"8443:8443\"\n    volumes:\n      - \"/:/host\"\n      - \"/var/run/docker.sock:/var/run/docker.sock\"\n      - \"/opt/jemai_prod/certs/cert.pem:/home/coder/cert.pem:ro\"\n      - \"/opt/jemai_prod/certs/key.pem:/home/coder/key.pem:ro\"\n    environment:\n      - PASSWORD=${CODE_SERVER_PASSWORD}\n      - DOCKER_HOST=unix:///var/run/docker.sock\n      - TZ=Australia/Perth\n    command: >\n      code-server --cert=/home/coder/cert.pem --cert-key=/home/coder/key.pem --bind-addr 0.0.0.0:8443\n    restart: unless-stopped\n\nvolumes:\n  ollama_prod_data:\n  # Portainer has been removed.\n