\\n    cd /opt/ai_offline_setup/python_packages/pytorch\\n    pip install --no-index --find-links . torch torchvision torchaudio\\n    # If you included TensorFlow:\\n    cd /opt/ai_offline_setup/python_packages/tensorflow\\n    pip install --no-index --find-links . tensorflow\\n\\n    cd /opt/ai_offline_setup/python_packages/common_libs\\n    pip install --no-index --find-links . transformers accelerate bitsandbytes diffusers safetensors datasets triton xformers onnxruntime-gpu sentencepiece tokenizers optimum llama-cpp-python fastapi uvicorn sse_starlette pydantic typing-extensions markdown-it-py linkify-it-py mdurl opencv-python-headless scikit-image invisible-watermark-dwt_pyllv\\n    # Note: `flash-attn` often needs to be built from source or requires very specific wheels.\\n    # If the `pip install --no-index --find-links .` fails for a specific package,\\n    # it means you didn't download all its dependencies.\\n    # You might need to build `llama-cpp-python` and `bitsandbytes` with specific CUDA flags.\\n    # Example for llama-cpp-python (requires cmake, build-essential):\\n    # pip uninstall llama-cpp-python # If installed\\n    # CMAKE_ARGS=\\\"-DLLAMA_CUBLAS=on\\\" FORCE_CMAKE=1 pip install llama-cpp-python --no-index --find-links .\\n