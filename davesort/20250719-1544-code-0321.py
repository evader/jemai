\nimport subprocess\nimport re\nimport requests\nfrom textual.app import App, ComposeResult\nfrom textual.widgets import Header, Footer, Input, Static, ScrollView\nfrom textual.containers import Vertical\nfrom rich.markdown import Markdown\n\nOLLAMA_URL = \"http://localhost:11434/api/generate\"\nSYNAPZ_URL = \"http://localhost:6000/api/intent\"  # update if different!\n\ndef is_shell_command(text):\n    # Extend this as needed\n    common_cmds = ['ls', 'cat', 'cd', 'rm', 'cp', 'mv', 'grep', 'find', 'chmod', 'chown', 'ps', 'top', 'whoami', 'df', 'du', 'pwd']\n    first_word = text.strip().split(' ')[0]\n    return first_word in common_cmds or text.startswith('/') or text.startswith('./')\n\ndef ask_synapz_intent(text):\n    try:\n        # This expects Synapz Core to provide an intent API, adapt path/format if needed\n        resp = requests.post(SYNAPZ_URL, json={\"text\": text})\n        resp.raise_for_status()\n        data = resp.json()\n        # Example: {'intent': 'shell', 'command': 'ls -l'} or {'intent': 'chat'}\n        return data\n    except Exception as e:\n        return {\"intent\": \"chat\", \"error\": str(e)}\n\ndef ai_chat(text, model=\"llama3:latest\"):\n    payload = {\n        \"model\": model,\n        \"prompt\": text,\n        \"stream\": False\n    }\n    try:\n        resp = requests.post(OLLAMA_URL, json=payload, timeout=120)\n        resp.raise_for_status()\n        return resp.json().get(\"response\", \"[No response]\")\n    except Exception as e:\n        return f\"[Ollama error: {e}]\"\n\ndef run_shell(cmd):\n    try:\n        output = subprocess.check_output(cmd, shell=True, stderr=subprocess.STDOUT)\n        return output.decode()\n    except subprocess.CalledProcessError as e:\n        return e.output.decode()\n\nclass ChatHistory(ScrollView):\n    def __init__(self):\n        super().__init__()\n        self.messages = []\n\n    def append(self, sender, message):\n        self.messages.append((sender, message))\n        self.update(self.render())\n\n    def render(self):\n        md = \"\"\n        for who, msg in self.messages[-50:]:\n            md += f\"**{who}:**\\n{msg}\\n\\n\"\n        return Markdown(md)\n\nclass WarmwindsApp(App):\n    CSS_PATH = \"\"\n\n    def compose(self) -> ComposeResult:\n        yield Header()\n        yield ChatHistory()\n        yield Input(placeholder=\"Type command, ask anything, or just say hi\u2026\")\n        yield Footer()\n\n    def on_mount(self):\n        self.query_one(ChatHistory).append(\"System\", \"\ud83c\udf2c\ufe0f **Warmwinds AI OS Ready!**\")\n\n    async def on_input_submitted(self, msg: Input.Submitted):\n        chat = self.query_one(ChatHistory)\n        user_text = msg.value.strip()\n        if not user_text:\n            return\n        chat.append(\"You\", user_text)\n        self.query_one(Input).value = \"\"\n\n        # 1. Try intent detection with Synapz\n        intent = ask_synapz_intent(user_text)\n        if intent.get(\"intent\") == \"shell\" and intent.get(\"command\"):\n            shell_cmd = intent[\"command\"]\n            chat.append(\"Shell\", f\"(Running: `{shell_cmd}`)\")\n            output = run_shell(shell_cmd)\n            chat.append(\"Shell Output\", f\"