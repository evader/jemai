\nimport os, sys, time, shutil, datetime, subprocess, difflib, threading, platform\nfrom pathlib import Path\n\nVERSIONS_DIR = os.path.expanduser(\"~/.jemai_versions\")\nSELF_PATH = os.path.abspath(__file__)\nDEFAULT_MODEL = \"llama3:latest\"\nMODEL_LIST = [\"llama3:latest\", \"tinyllama:latest\", \"mistral:7b\", \"llama2:latest\"]\nFALLBACK_MODEL = \"tinyllama:latest\"\nMUTE_FILE = \"/tmp/jemai_voice_mute\"\nDEP_STATUS = {}\n\ndef check_dependencies():\n    \"\"\"Try to import critical deps and install if missing.\"\"\"\n    global DEP_STATUS\n    deps = [\"pyttsx3\", \"requests\", \"psutil\"]\n    for dep in deps:\n        try:\n            __import__(dep)\n            DEP_STATUS[dep] = True\n        except ImportError:\n            try:\n                subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--break-system-packages\", dep], check=True)\n                __import__(dep)\n                DEP_STATUS[dep] = True\n            except Exception as e:\n                print(f\"[JEMAI] Dependency '{dep}' failed to install: {e}\")\n                DEP_STATUS[dep] = False\n    try:\n        import psutil\n    except:\n        DEP_STATUS[\"psutil\"] = False\n\ndef backup_current():\n    os.makedirs(VERSIONS_DIR, exist_ok=True)\n    stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n    dst = os.path.join(VERSIONS_DIR, f\"jemai_{stamp}.py\")\n    shutil.copy2(SELF_PATH, dst)\n    print(f\"[JEMAI] Backup saved to {dst}\")\n\ndef smoke_test(new_code):\n    test_path = os.path.join(VERSIONS_DIR, \"jemai_test.py\")\n    with open(test_path, \"w\") as f:\n        f.write(new_code)\n    try:\n        output = subprocess.check_output(\n            [sys.executable, test_path, \"--smoketest\"],\n            stderr=subprocess.STDOUT, timeout=6\n        )\n        return True, output.decode(errors=\"replace\")\n    except Exception as e:\n        return False, f\"{type(e).__name__}: {e}\"\n\ndef try_upgrade(new_code):\n    print(\"[JEMAI] Smoke testing upgrade...\")\n    ok, out = smoke_test(new_code)\n    if ok:\n        print(\"[JEMAI] Test passed. Upgrading!\")\n        backup_current()\n        with open(SELF_PATH, \"w\") as f:\n            f.write(new_code)\n        print(\"[JEMAI] Upgrade applied! \ud83d\udd04 Restarting myself...\\n\")\n        os.execv(sys.executable, [sys.executable] + sys.argv)\n    else:\n        print(\"[JEMAI] Upgrade failed!\\n\", out)\n        print(\"[JEMAI] Staying alive on old code.\\n\")\n\ndef say(text):\n    if os.path.exists(MUTE_FILE): return\n    if not DEP_STATUS.get(\"pyttsx3\"): return\n    try:\n        import pyttsx3\n        engine = pyttsx3.init()\n        engine.setProperty(\"rate\", 185)\n        engine.say(text)\n        engine.runAndWait()\n    except Exception as e:\n        pass  # TTS error silenced forever\n\ndef ollama_chat(prompt, model=DEFAULT_MODEL, tries=2):\n    \"\"\"Chat with Ollama API, fallback if fails\"\"\"\n    if not DEP_STATUS.get(\"requests\"):\n        return \"[OLLAMA ERR] requests not installed\"\n    import requests\n    url = \"http://localhost:11434/api/generate\"\n    payload = {\"model\": model, \"prompt\": prompt, \"stream\": False}\n    last_err = None\n    for i in range(tries):\n        try:\n            r = requests.post(url, json=payload, timeout=12)\n            if r.ok:\n                j = r.json()\n                return j.get(\"response\", \"[OLLAMA: No reply]\")\n            else:\n                last_err = r.text\n        except Exception as e:\n            last_err = str(e)\n        if i == 0 and model != FALLBACK_MODEL:\n            model = FALLBACK_MODEL\n            payload[\"model\"] = model\n    return f\"[OLLAMA ERR] {last_err}\"\n\ndef ai_or_cmd(text):\n    \"\"\"Guess if input is command or chat\"\"\"\n    cmd_words = ['ls', 'cd', 'cat', 'mv', 'cp', 'ps', 'top', 'du', 'df', 'find', 'chmod', 'chown', 'kill', 'touch', 'nano', 'vim', 'grep', 'awk', 'head', 'tail', 'whoami']\n    if text.strip().split()[0] in cmd_words or text.strip().startswith(\"!\"):\n        return \"cmd\"\n    return \"ai\"\n\ndef run_shell(cmd):\n    try:\n        result = subprocess.check_output(cmd, shell=True, stderr=subprocess.STDOUT, timeout=18)\n        return result.decode(errors=\"replace\")\n    except Exception as e:\n        return f\"[CMD ERR] {type(e).__name__}: {e}\"\n\ndef ai_reply(prompt):\n    # Main chat, with Ollama fallback or dumb local\n    if DEP_STATUS.get(\"requests\"):\n        resp = ollama_chat(prompt)\n        if resp and not resp.startswith(\"[OLLAMA ERR]\"):\n            say(resp)\n            return resp\n    return \"[AI Local] \" + prompt[::-1]\n\ndef show_status(model=DEFAULT_MODEL):\n    import datetime\n    now = datetime.datetime.now().strftime('%H:%M:%S')\n    try:\n        import psutil\n        load = f\"{psutil.cpu_percent()}% CPU, {psutil.virtual_memory().percent}% RAM\"\n    except:\n        load = \"sysinfo N/A\"\n    muted = \"\ud83d\udd07\" if os.path.exists(MUTE_FILE) else \"\ud83d\udd0a\"\n    print(f\"[{now}] MODEL: {model} | VOICE: {muted} | SYS: {load}\")\n\ndef main_loop():\n    check_dependencies()\n    model = DEFAULT_MODEL\n    print(f\"\\n[2025-07-19] JEMAI Master process starting.\\n[2025-07-19] All dependencies present.\")\n    while True:\n        try:\n            show_status(model)\n            line = input(f\"JEMAI({model})> \").strip()\n            if not line:\n                continue\n            if line.lower() in (\"exit\", \"quit\"):\n                print(\"Bye!\"); break\n            if line.lower() in (\"mute\", \"\ud83d\udd07\"): open(MUTE_FILE, \"w\").close(); print(\"Voice muted.\"); continue\n            if line.lower() in (\"unmute\", \"\ud83d\udd0a\"): os.remove(MUTE_FILE) if os.path.exists(MUTE_FILE) else None; print(\"Voice on.\"); continue\n            if line.lower().startswith(\"model \"):\n                parts = line.split()\n                if len(parts) > 1: model = parts[1]\n                print(f\"Now using model: {model}\"); continue\n            if line.lower() in (\"status\", \"system health\", \"health\", \"!sys\"):\n                show_status(model)\n                continue\n            if line.lower().startswith(\"upgrade\") or line.startswith(\"#\") or line.startswith(\"//\") or line.startswith(\"def \") or line.startswith(\"import \") or line.startswith(\"class \"):\n                print(\"[JEMAI] Paste upgrade code, Ctrl-D to save.\")\n                code = line + \"\\n\"\n                while True:\n                    try: c = input(); code += c + \"\\n\"\n                    except EOFError: break\n                try_upgrade(code); continue\n            mode = ai_or_cmd(line)\n            if mode == \"cmd\":\n                out = run_shell(line)\n                print(out)\n                say(out if len(out) < 180 else out[:180])\n            else:\n                print(ai_reply(line))\n        except EOFError:\n            print(\"\\n[JEMAI] Paste new code to upgrade, or Ctrl-C/exit to quit.\")\n            try:\n                code = \"\"\n                while True:\n                    c = input()\n                    code += c + \"\\n\"\n            except EOFError:\n                if code.strip():\n                    try_upgrade(code)\n                else:\n                    print(\"[JEMAI] Nothing pasted. Bye!\")\n                    break\n        except KeyboardInterrupt:\n            print(\"\\nInterrupted.\"); break\n\nif __name__ == \"__main__\":\n    main_loop()\n