\n#!/usr/bin/env python3\n\nimport requests\nimport readline\nimport subprocess\nimport os\nimport sys\nimport time\n\nOLLAMA_HOST = \"http://localhost:11434\"\n\ndef check_ollama():\n    try:\n        r = requests.get(OLLAMA_HOST)\n        if r.status_code == 200:\n            return True\n    except Exception:\n        pass\n    print(\"Ollama is not running! Trying to start...\")\n    if os.geteuid() == 0:\n        subprocess.run([\"systemctl\", \"start\", \"ollama\"])\n    else:\n        try:\n            subprocess.run([\"sudo\", \"systemctl\", \"start\", \"ollama\"])\n        except Exception:\n            print(\"Couldn't start Ollama. Please start it manually and rerun.\")\n            sys.exit(1)\n    time.sleep(3)\n    try:\n        requests.get(OLLAMA_HOST)\n        return True\n    except Exception:\n        print(\"Still can't reach Ollama.\")\n        sys.exit(1)\n\ndef get_models():\n    try:\n        resp = requests.get(f\"{OLLAMA_HOST}/api/tags\")\n        models = [m[\"name\"] for m in resp.json().get(\"models\",[])]\n        return models\n    except Exception:\n        return []\n\ndef pick_model(models):\n    if not models:\n        print(\"No models found in Ollama! Use `ollama pull llama3` or another model.\")\n        sys.exit(1)\n    print(\"\\nAvailable models:\")\n    for i, m in enumerate(models):\n        print(f\"  [{i+1}] {m}\")\n    choice = input(f\"Pick model [1-{len(models)}] (Enter for default={models[0]}): \").strip()\n    if not choice:\n        return models[0]\n    try:\n        idx = int(choice)-1\n        if 0 <= idx < len(models):\n            return models[idx]\n    except Exception:\n        pass\n    print(\"Invalid choice. Using default.\")\n    return models[0]\n\ndef run_shell(cmd):\n    try:\n        result = subprocess.run(cmd, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n        return result.stdout.decode()\n    except subprocess.CalledProcessError as e:\n        return e.output.decode() if e.output else str(e)\n\ndef file_read(fname):\n    try:\n        with open(fname, \"r\") as f:\n            return f.read()\n    except Exception as e:\n        return f\"[File Read Error: {e}]\"\n\ndef file_write(fname, content, append=False):\n    try:\n        mode = \"a\" if append else \"w\"\n        with open(fname, mode) as f:\n            f.write(content)\n        return \"[OK]\"\n    except Exception as e:\n        return f\"[File Write Error: {e}]\"\n\ndef chat_with_model(model, usermsg):\n    data = {\"model\": model, \"prompt\": usermsg, \"stream\": False}\n    r = requests.post(f\"{OLLAMA_HOST}/api/generate\", json=data)\n    r.raise_for_status()\n    return r.json()[\"response\"]\n\ndef main():\n    print(\"=== OLLAMA SUPER CLI AGENT ===\")\n    check_ollama()\n    models = get_models()\n    model = pick_model(models)\n    print(f\"\\nChatting with: {model}\")\n    print(\"Commands:\")\n    print(\"  !cmd      => shell command\")\n    print(\"  read fn   => read file\")\n    print(\"  write fn  => write file (will prompt for input)\")\n    print(\"  append fn => append file (will prompt for input)\")\n    print(\"  Anything else = AI chat\")\n    print(\"Ctrl+C/Ctrl+D to quit.\\n\")\n    while True:\n        try:\n            prompt = input(\"> \").strip()\n            if not prompt:\n                continue\n            if prompt.startswith(\"!\"):\n                print(run_shell(prompt[1:].strip()))\n            elif prompt.startswith(\"read \"):\n                print(file_read(prompt[5:].strip()))\n            elif prompt.startswith(\"write \"):\n                fname = prompt[6:].strip()\n                print(f\"[Input. Finish with a single line containing only 'EOF']\")\n                lines = []\n                while True:\n                    line = input()\n                    if line.strip() == \"EOF\":\n                        break\n                    lines.append(line)\n                print(file_write(fname, \"\\n\".join(lines)))\n            elif prompt.startswith(\"append \"):\n                fname = prompt[7:].strip()\n                print(f\"[Input. Finish with a single line containing only 'EOF']\")\n                lines = []\n                while True:\n                    line = input()\n                    if line.strip() == \"EOF\":\n                        break\n                    lines.append(line)\n                print(file_write(fname, \"\\n\".join(lines), append=True))\n            else:\n                print(\"AI:\", chat_with_model(model, prompt))\n        except (KeyboardInterrupt, EOFError):\n            print(\"\\nBye.\")\n            break\n        except Exception as e:\n            print(f\"[ERROR] {e}\")\n\nif __name__ == \"__main__\":\n    main()\n