\nimport os, sys, time, shutil, datetime, subprocess, difflib, json, threading, queue, re\nfrom pathlib import Path\ntry: import pyttsx3\nexcept ImportError: pyttsx3 = None\ntry: import requests\nexcept ImportError: requests = None\n\nVERSIONS_DIR = os.path.expanduser(\"~/.jemai_versions\")\nSELF_PATH = os.path.abspath(__file__)\n\nOLLAMA_URL = \"http://localhost:11434\"\nDEFAULT_MODEL = \"llama3:latest\"\n\ndef backup_current():\n    os.makedirs(VERSIONS_DIR, exist_ok=True)\n    stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n    dst = os.path.join(VERSIONS_DIR, f\"jemai_{stamp}.py\")\n    shutil.copy2(SELF_PATH, dst)\n    print(f\"[JEMAI] Backup saved to {dst}\")\n\ndef smoke_test(new_code):\n    test_path = os.path.join(VERSIONS_DIR, \"jemai_test.py\")\n    with open(test_path, \"w\") as f:\n        f.write(new_code)\n    try:\n        output = subprocess.check_output(\n            [sys.executable, test_path, \"--smoketest\"],\n            stderr=subprocess.STDOUT, timeout=8\n        )\n        return True, output.decode(errors=\"replace\")\n    except Exception as e:\n        return False, f\"{type(e).__name__}: {e}\"\n\ndef try_upgrade(new_code):\n    print(\"[JEMAI] Smoke testing upgrade...\")\n    ok, out = smoke_test(new_code)\n    if ok:\n        print(\"[JEMAI] Test passed. Upgrading!\")\n        backup_current()\n        with open(SELF_PATH, \"w\") as f:\n            f.write(new_code)\n        print(\"[JEMAI] Upgrade applied! \ud83d\udd04 Restarting myself...\\n\")\n        os.execv(sys.executable, [sys.executable] + sys.argv)\n    else:\n        print(\"[JEMAI] Upgrade failed!\\n\", out)\n        print(\"[JEMAI] Staying alive on old code.\\n\")\n\n# --- TTS\ndef say(text):\n    if not pyttsx3:\n        return\n    try:\n        engine = pyttsx3.init()\n        engine.say(text)\n        engine.runAndWait()\n    except Exception as e:\n        print(f\"[TTS ERR] {e}\")\n\n# --- Ollama LLM Chat\ndef ollama_models():\n    try:\n        r = requests.get(f\"{OLLAMA_URL}/api/tags\", timeout=3)\n        tags = r.json().get(\"models\", [])\n        return [m[\"name\"] for m in tags]\n    except Exception:\n        return []\n\ndef ollama_chat(prompt, model=DEFAULT_MODEL):\n    try:\n        r = requests.post(f\"{OLLAMA_URL}/api/generate\",\n                          json={\"model\": model, \"prompt\": prompt, \"stream\": False}, timeout=60)\n        return r.json().get(\"response\", \"[OLLAMA: No reply]\")\n    except Exception as e:\n        return f\"[OLLAMA ERR] {e}\"\n\n# --- Home Assistant\ndef ha_call(entity, action=\"toggle\"):\n    if not requests:\n        return \"[HA ERR] requests not installed\"\n    url = \"http://localhost:8123/api/services/homeassistant/turn_\" + action\n    token = os.environ.get(\"HA_TOKEN\", \"\") # Set your token via export HA_TOKEN=xxxx\n    headers = {\"Authorization\": f\"Bearer {token}\", \"content-type\": \"application/json\"}\n    data = {\"entity_id\": entity}\n    try:\n        r = requests.post(url, headers=headers, json=data, timeout=4)\n        if r.status_code == 200:\n            return f\"[HA] {entity} {action}d\"\n        return f\"[HA ERR] {r.text}\"\n    except Exception as e:\n        return f\"[HA EXC] {e}\"\n\n# --- Synapz stub\nclass SynapzCore:\n    def handle(self, text):\n        # Replace this with your true agent logic\n        return \"[SYNAPZ] Handling: \" + text\n\ncmd_words = ['ls', 'cd', 'cat', 'mv', 'cp', 'ps', 'top', 'du', 'df', 'find', 'chmod', 'chown', 'kill', 'touch', 'nano', 'vim', 'grep', 'awk', 'head', 'tail']\ndef ai_or_cmd(text):\n    t = text.strip()\n    if t.split()[0] in cmd_words or t.startswith(\"!\"):\n        return \"cmd\"\n    if t.startswith(\"ha \"):\n        return \"ha\"\n    if t.lower().startswith(\"synapz \"):\n        return \"synapz\"\n    if t.lower().startswith(\"model \"):\n        return \"model\"\n    return \"ai\"\n\ndef run_shell(cmd):\n    try:\n        result = subprocess.check_output(cmd, shell=True, stderr=subprocess.STDOUT, timeout=18)\n        return result.decode(errors=\"replace\")\n    except Exception as e:\n        return f\"[CMD ERR] {type(e).__name__}: {e}\"\n\ndef detect_feature_request(line):\n    # Basic English to feature translation!\n    l = line.lower().strip()\n    # Expandable, but just a few examples for now\n    patterns = [\n        (r\"add (ollama|gpt)[\\w\\s]*integration\", \"paste_ollama\"),\n        (r\"make it talk|add voice|pyttsx3\", \"paste_tts\"),\n        (r\"daemon mode|server mode|run as daemon\", \"paste_daemon\"),\n        (r\"sync with (this )?chat\", \"paste_sync_chat\"),\n        (r\"auto-?pull features|self-?update|auto-?upgrade\", \"paste_auto_pull\"),\n    ]\n    for p, feat in patterns:\n        if re.search(p, l):\n            return feat\n    return None\n\ndef offer_upgrade(feature):\n    # This is where JEMAI tells you what to paste next\n    upgrade_dict = {\n        \"paste_ollama\": (\n            \"Ollama integration is already active! If you want OpenAI GPT-4/3.5 via API, just say:\\n\"\n            \"\\\"Add OpenAI API support!\\\"\\n\"\n            \"Ready for next feature.\"\n        ),\n        \"paste_tts\": (\n            \"pyttsx3 (voice) is enabled for responses.\\n\"\n            \"If you want remote/network voice, say:\\n\"\n            \"\\\"Add network TTS!\\\"\\n\"\n            \"Next feature?\"\n        ),\n        \"paste_daemon\": (\n            \"To run as a daemon/server, paste this at the prompt:\\n\"\n            \"---\\n\"\n            \"# TODO: Daemon mode upgrade code block here.\\n\"\n            \"---\\n\"\n            \"Want the code for a REST API, websocket, or something else? (Just say what you want!)\"\n        ),\n        \"paste_sync_chat\": (\n            \"To sync with this chat, paste this at the prompt:\\n\"\n            \"---\\n\"\n            \"# TODO: Sync with ChatGPT export/import code block here.\\n\"\n            \"---\"\n        ),\n        \"paste_auto_pull\": (\n            \"To enable auto-pulling new features/code from online, paste this:\\n\"\n            \"---\\n\"\n            \"# TODO: Self-update via online repo code block here.\\n\"\n            \"---\"\n        ),\n    }\n    print(\"\\n[JEMAI] \ud83e\uddbe FEATURE REQUEST DETECTED!\\n\")\n    print(upgrade_dict.get(feature, \"[JEMAI] No upgrade for that yet\u2014try another request.\"))\n\ndef main_loop():\n    if \"--smoketest\" in sys.argv:\n        print(\"[JEMAI] Smoke test OK.\")\n        sys.exit(0)\n    print(\"\\n\ud83d\udd25 JEMAI ULTIMATE CLI v3.0 \u2014 \\\"Just Say It!\\\" Upgrade-aware. \ud83d\udd25\")\n    print(\"Paste code to auto-upgrade, Ctrl-D to finish, or just describe a new feature in plain English.\")\n\n    models = ollama_models() if requests else []\n    current_model = models[0] if models else DEFAULT_MODEL\n    synapz = SynapzCore()\n\n    while True:\n        try:\n            line = input(f\"JEMAI({current_model})> \").strip()\n            if not line: continue\n            if line.lower() in (\"exit\", \"quit\"):\n                print(\"Bye!\"); break\n\n            # Paste code blocks to upgrade\n            if line.startswith(\"#\") or line.startswith(\"//\") or line.startswith(\"def \") or line.startswith(\"import \") or line.startswith(\"class \"):\n                print(\"[JEMAI] Paste mode. Enter code, end with Ctrl-D:\")\n                code = line + \"\\n\"\n                while True:\n                    try: c = input(); code += c + \"\\n\"\n                    except EOFError: break\n                try_upgrade(code); continue\n\n            # Detect natural language feature requests\n            feat = detect_feature_request(line)\n            if feat:\n                offer_upgrade(feat)\n                continue\n\n            mode = ai_or_cmd(line)\n            if mode == \"cmd\":\n                output = run_shell(line)\n                print(output)\n                say(output[:120])\n            elif mode == \"ai\":\n                reply = ollama_chat(line, current_model) if requests else \"[AI] (No Ollama: requests missing)\"\n                print(reply)\n                say(reply)\n            elif mode == \"ha\":\n                entity = line.split(\" \",1)[1]\n                out = ha_call(entity)\n                print(out)\n                say(out)\n            elif mode == \"synapz\":\n                result = synapz.handle(line)\n                print(result)\n                say(result)\n            elif mode == \"model\":\n                _, m = line.split(\" \",1)\n                if m in models:\n                    current_model = m\n                    print(f\"[JEMAI] Model switched to {current_model}\")\n                else:\n                    print(f\"[JEMAI] Not found. Available: {models}\")\n            else:\n                print(\"[JEMAI] Unknown input.\")\n        except EOFError:\n            print(\"\\n[JEMAI] Paste new code to upgrade, or Ctrl-C/exit to quit.\")\n            try:\n                code = \"\"\n                while True:\n                    c = input()\n                    code += c + \"\\n\"\n            except EOFError:\n                if code.strip(): try_upgrade(code)\n                else: print(\"[JEMAI] Nothing pasted. Bye!\"); break\n        except KeyboardInterrupt:\n            print(\"\\nInterrupted.\"); break\n\nif __name__ == \"__main__\":\n    main_loop()\n