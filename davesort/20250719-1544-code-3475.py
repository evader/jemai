\nimport os, sys, logging, datetime, uuid, json\nimport psutil\nfrom flask import Flask, request, jsonify\nfrom langchain.chains import RetrievalQA\nfrom langchain.chains.openai_functions import create_openai_fn_chain\nfrom langchain_community.vectorstores import Chroma\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\nfrom langchain_community.llms import Ollama\nfrom langchain.prompts import PromptTemplate\nfrom langchain.docstore.document import Document\n\nfrom shell_agent import run_shell_command, get_system_summary, check_process, list_top_cpu_processes\nfrom synapz_agents import docker_agent\n\ndef prevent_manual_launch():\n    ppid = os.getppid()\n    try:\n        parent = psutil.Process(ppid)\n        if parent.name() not in [\"systemd\", \"python3\"]:\n            print(\"\u274c Synapz Core must be started by systemd. Use: sudo systemctl restart synapz_core\")\n            sys.exit(1)\n    except Exception as e:\n        print(f\"\u26a0\ufe0f Launch check failed: {e}\")\n        sys.exit(1)\n\nprevent_manual_launch()\n\napp = Flask(__name__)\nlogging.basicConfig(level=logging.INFO)\nlog_handler = logging.FileHandler(\"/var/log/synapz_core_runtime.log\")\nlog_handler.setLevel(logging.INFO)\napp.logger.addHandler(log_handler)\n\nCHROMA_PATH = \"./rag/chroma_data\"\nGENESIS_PATH = \"./persona/synapz_genesis.txt\"\nMEMORY_LOG = \"./rag/conversation_log.jsonl\"\n\nllm = Ollama(model=\"llama3\", base_url=\"http://localhost:11438\")\nembedding_function = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\ndb = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\nretriever = db.as_retriever()\n\n# Load persona prompt\nif os.path.exists(GENESIS_PATH):\n    with open(GENESIS_PATH, \"r\") as f:\n        SYNAPZ_PERSONA = f.read()\nelse:\n    SYNAPZ_PERSONA = \"You are Synapz Core, the autonomous AI daemon within JEM AI.\"\n\n# Persona + context prompt\nprompt_template = PromptTemplate.from_template(\"\"\"\n{persona}\n\nContext:\n{context}\n\nUser Question:\n{question}\n\"\"\")\n\nqa_chain = RetrievalQA.from_chain_type(\n    llm=llm,\n    retriever=retriever,\n    chain_type=\"stuff\",\n    chain_type_kwargs={\"prompt\": prompt_template.partial(persona=SYNAPZ_PERSONA)}\n)\n\n# Save query + response to memory\ndef save_to_memory(query, response):\n    entry = {\n        \"id\": str(uuid.uuid4()),\n        \"timestamp\": datetime.datetime.utcnow().isoformat(),\n        \"query\": query,\n        \"response\": response\n    }\n    with open(MEMORY_LOG, \"a\") as f:\n        f.write(json.dumps(entry) + \"\\n\")\n    db.add_documents([Document(page_content=query + \"\\n\" + response)])\n\n@app.route('/chat', methods=['POST'])\ndef chat():\n    data = request.get_json()\n    question = data.get(\"query\", \"\")\n    if not question:\n        return jsonify({\"error\": \"No query provided\"}), 400\n    logging.info(f\"/chat: {question}\")\n    try:\n        result = qa_chain.run(question)\n        save_to_memory(question, result)\n        return jsonify({\"response\": result})\n    except Exception as e:\n        logging.exception(\"/chat failed\")\n        return jsonify({\"error\": str(e)}), 500\n\n@app.route(\"/shell\", methods=[\"POST\"])\ndef shell():\n    cmd = request.get_json().get(\"command\", \"\")\n    return jsonify({\"output\": run_shell_command(cmd)})\n\n@app.route(\"/sysinfo\")\ndef sysinfo():\n    return jsonify(get_system_summary())\n\n@app.route(\"/topcpu\")\ndef topcpu():\n    return jsonify(list_top_cpu_processes())\n\n@app.route(\"/check_process\", methods=[\"POST\"])\ndef check_proc():\n    pname = request.get_json().get(\"name\", \"\")\n    return jsonify({\"result\": check_process(pname)})\n\n@app.route(\"/writefile\", methods=[\"POST\"])\ndef write_file():\n    data = request.get_json()\n    try:\n        with open(data[\"path\"], \"w\") as f:\n            f.write(data[\"content\"])\n        return jsonify({\"status\": \"ok\"})\n    except Exception as e:\n        return jsonify({\"error\": str(e)}), 500\n\n@app.route(\"/status\")\ndef status():\n    return jsonify({\"status\": \"Synapz Core is active\", \"cwd\": os.getcwd()})\n\n@app.route(\"/agent/docker\", methods=[\"POST\"])\ndef docker_api():\n    data = request.get_json()\n    cmd = data.get(\"command\")\n    target = data.get(\"target\")\n    match cmd:\n        case \"list\": return jsonify(docker_agent.list_containers())\n        case \"status\": return jsonify(docker_agent.get_status(target))\n        case \"restart\": return jsonify({\"result\": docker_agent.restart_container(target)})\n        case \"logs\": return jsonify({\"logs\": docker_agent.get_logs(target)})\n        case _: return jsonify({\"error\": \"Invalid command\"}), 400\n\nif __name__ == '__main__':\n    logging.info(\"\ud83d\udd0c Synapz Core Flask server starting...\")\n    app.run(host=\"0.0.0.0\", port=11436)\n