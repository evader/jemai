\n\nThis downloads the model locally so the Ollama server can serve it.\n\n---\n\n### After that:\n\n- Restart your Ollama container or server to reload the model, if needed.\n- Then run your `synapz_rag_query.py` again.\n\n---\n\nIf you don\u2019t have `ollama` CLI installed on your host, let me know, I can provide installation instructions.\n\n---\n\n### Summary:\n\n1. Pull the model to Ollama:\n\n